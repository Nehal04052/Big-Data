{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8622a211-e5f8-47d9-b642-7d6226a9e91f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Fish Weight Prediction\n",
    "\n",
    "##### With a dataset of fish species, with some of it characteristic like it vertical, diagonal, length, height, and width. We will try to predict the weight of the fish based on their characteristic. We will use Linear Regression Method to see whether the weight of the fish related to their characteristic.\n",
    "\n",
    "1. **Species**: Species name of fish\n",
    "2. **Weight**: Weight of fish in gram\n",
    "3. **Length1**: Vertical length in cm\n",
    "4. **Length2**: Diagonal length in cm\n",
    "5. **Length3**: Cross length in cm\n",
    "6. **Height**: Height in cm\n",
    "7. **Width**: Diagonal width in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b15dfe6-2592-4b80-bc77-570fe32e91f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/FileStore/tables/Admission_Chance.csv', name='Admission_Chance.csv', size=12905, modificationTime=1720190058000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/Cancer.csv', name='Cancer.csv', size=125204, modificationTime=1720190099000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/Credit_Default.csv', name='Credit_Default.csv', size=101152, modificationTime=1720190106000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/Customer_Purchase.csv', name='Customer_Purchase.csv', size=1489, modificationTime=1720190113000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/Fish.csv', name='Fish.csv', size=6349, modificationTime=1720190119000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/Ice_Cream.csv', name='Ice_Cream.csv', size=4872, modificationTime=1720190124000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/Test1.csv', name='Test1.csv', size=108, modificationTime=1720158698000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/Test2.csv', name='Test2.csv', size=192, modificationTime=1720158698000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/Test3.csv', name='Test3.csv', size=388, modificationTime=1720158699000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/Test4.csv', name='Test4.csv', size=143, modificationTime=1720158699000),\n",
       " FileInfo(path='dbfs:/FileStore/tables/Test5.csv', name='Test5.csv', size=262, modificationTime=1720158699000)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"dbfs:/FileStore/tables/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8ed0c61-2cfa-42b6-baa6-f3a2d93ce185",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, abs\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a7b7310-65f3-4c95-9700-36a811386eeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Fish Weight Prediction').getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6004644f-ac61-4d25-8f85-bad24a40bad2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=3338812497204728#setting/sparkui/0707-033416-dzfopq7d/driver-4352685867671526617\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7faceaef2e00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aebb0197-8bc1-420a-ad5f-5dc518e04746",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('dbfs:/FileStore/tables/Fish.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c55781b-1883-47c1-945d-7c6e7f8a1be9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Category: integer (nullable = true)\n |-- Species: string (nullable = true)\n |-- Weight: double (nullable = true)\n |-- Height: double (nullable = true)\n |-- Width: double (nullable = true)\n |-- Length1: double (nullable = true)\n |-- Length2: double (nullable = true)\n |-- Length3: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c17ceb54-e04c-4fa0-a1f7-ac98c02cf39b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[Category: int, Species: string, Weight: double, Height: double, Width: double, Length1: double, Length2: double, Length3: double]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d41aba58-ed58-4e52-8f22-23a66f44b630",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------+-------+------+-------+-------+-------+\n|Category|Species|Weight| Height| Width|Length1|Length2|Length3|\n+--------+-------+------+-------+------+-------+-------+-------+\n|       1|  Bream| 242.0|  11.52|  4.02|   23.2|   25.4|   30.0|\n|       1|  Bream| 290.0|  12.48|4.3056|   24.0|   26.3|   31.2|\n|       1|  Bream| 340.0|12.3778|4.6961|   23.9|   26.5|   31.1|\n|       1|  Bream| 363.0|  12.73|4.4555|   26.3|   29.0|   33.5|\n|       1|  Bream| 430.0| 12.444| 5.134|   26.5|   29.0|   34.0|\n|       1|  Bream| 450.0|13.6024|4.9274|   26.8|   29.7|   34.7|\n|       1|  Bream| 500.0|14.1795|5.2785|   26.8|   29.7|   34.5|\n|       1|  Bream| 390.0|  12.67|  4.69|   27.6|   30.0|   35.0|\n|       1|  Bream| 450.0|14.0049|4.8438|   27.6|   30.0|   35.1|\n|       1|  Bream| 500.0|14.2266|4.9594|   28.5|   30.7|   36.2|\n|       1|  Bream| 475.0|14.2628|5.1042|   28.4|   31.0|   36.2|\n|       1|  Bream| 500.0|14.3714|4.8146|   28.7|   31.0|   36.2|\n|       1|  Bream| 500.0|13.7592| 4.368|   29.1|   31.5|   36.4|\n|       1|  Bream| 340.0|13.9129|5.0728|   29.5|   32.0|   37.3|\n|       1|  Bream| 600.0|14.9544|5.1708|   29.4|   32.0|   37.2|\n|       1|  Bream| 600.0| 15.438|  5.58|   29.4|   32.0|   37.2|\n|       1|  Bream| 700.0|14.8604|5.2854|   30.4|   33.0|   38.3|\n|       1|  Bream| 700.0| 14.938|5.1975|   30.4|   33.0|   38.5|\n|       1|  Bream| 610.0| 15.633|5.1338|   30.9|   33.5|   38.6|\n|       1|  Bream| 650.0|14.4738|5.7276|   31.0|   33.5|   38.7|\n+--------+-------+------+-------+------+-------+-------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b57cfb47-da11-420a-be71-b3535b394cb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. Clean the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e8488d5-a6f5-4fc0-bb12-858b50eea62e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Handle missing values if necessary\n",
    "df_pyspark = df_pyspark.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4e0dbc4-2f9b-4ffe-a29c-8997a9f74b82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Category',\n",
       " 'Species',\n",
       " 'Weight',\n",
       " 'Height',\n",
       " 'Width',\n",
       " 'Length1',\n",
       " 'Length2',\n",
       " 'Length3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8719edfc-52a8-4fe3-91ec-2896f0234531",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.select('Category','Weight','Height','Width','Length1','Length2','Length3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24e6fcfb-47ca-458a-95a8-e2c4fcc1983a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+------+-------+-------+-------+\n|Category|Weight| Height| Width|Length1|Length2|Length3|\n+--------+------+-------+------+-------+-------+-------+\n|       1| 242.0|  11.52|  4.02|   23.2|   25.4|   30.0|\n|       1| 290.0|  12.48|4.3056|   24.0|   26.3|   31.2|\n|       1| 340.0|12.3778|4.6961|   23.9|   26.5|   31.1|\n|       1| 363.0|  12.73|4.4555|   26.3|   29.0|   33.5|\n|       1| 430.0| 12.444| 5.134|   26.5|   29.0|   34.0|\n|       1| 450.0|13.6024|4.9274|   26.8|   29.7|   34.7|\n|       1| 500.0|14.1795|5.2785|   26.8|   29.7|   34.5|\n|       1| 390.0|  12.67|  4.69|   27.6|   30.0|   35.0|\n|       1| 450.0|14.0049|4.8438|   27.6|   30.0|   35.1|\n|       1| 500.0|14.2266|4.9594|   28.5|   30.7|   36.2|\n|       1| 475.0|14.2628|5.1042|   28.4|   31.0|   36.2|\n|       1| 500.0|14.3714|4.8146|   28.7|   31.0|   36.2|\n|       1| 500.0|13.7592| 4.368|   29.1|   31.5|   36.4|\n|       1| 340.0|13.9129|5.0728|   29.5|   32.0|   37.3|\n|       1| 600.0|14.9544|5.1708|   29.4|   32.0|   37.2|\n|       1| 600.0| 15.438|  5.58|   29.4|   32.0|   37.2|\n|       1| 700.0|14.8604|5.2854|   30.4|   33.0|   38.3|\n|       1| 700.0| 14.938|5.1975|   30.4|   33.0|   38.5|\n|       1| 610.0| 15.633|5.1338|   30.9|   33.5|   38.6|\n|       1| 650.0|14.4738|5.7276|   31.0|   33.5|   38.7|\n+--------+------+-------+------+-------+-------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab75b06d-0811-4268-a1dd-66c8cda6f9d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Category: integer (nullable = true)\n |-- Weight: double (nullable = true)\n |-- Height: double (nullable = true)\n |-- Width: double (nullable = true)\n |-- Length1: double (nullable = true)\n |-- Length2: double (nullable = true)\n |-- Length3: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34bb6b12-a912-4f0f-81d0-9d7ed0077c23",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Prepare the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef0f0f44-c167-441e-a538-899b21d545b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the feature columns\n",
    "feature_columns = ['Category','Height','Width','Length1','Length2','Length3']\n",
    "\n",
    "# Assemble features into a single vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_pyspark = assembler.transform(df_pyspark)\n",
    "\n",
    "# Select only the features and target column\n",
    "df_pyspark = df_pyspark.select(\"features\", \"Weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b10513-7db1-4d87-bba8-9e24abbb5faf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n|            features|Weight|\n+--------------------+------+\n|[1.0,11.52,4.02,2...| 242.0|\n|[1.0,12.48,4.3056...| 290.0|\n|[1.0,12.3778,4.69...| 340.0|\n|[1.0,12.73,4.4555...| 363.0|\n|[1.0,12.444,5.134...| 430.0|\n|[1.0,13.6024,4.92...| 450.0|\n|[1.0,14.1795,5.27...| 500.0|\n|[1.0,12.67,4.69,2...| 390.0|\n|[1.0,14.0049,4.84...| 450.0|\n|[1.0,14.2266,4.95...| 500.0|\n|[1.0,14.2628,5.10...| 475.0|\n|[1.0,14.3714,4.81...| 500.0|\n|[1.0,13.7592,4.36...| 500.0|\n|[1.0,13.9129,5.07...| 340.0|\n|[1.0,14.9544,5.17...| 600.0|\n|[1.0,15.438,5.58,...| 600.0|\n|[1.0,14.8604,5.28...| 700.0|\n|[1.0,14.938,5.197...| 700.0|\n|[1.0,15.633,5.133...| 610.0|\n|[1.0,14.4738,5.72...| 650.0|\n+--------------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36942845-e2ea-4986-abbb-da4f9b1501d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 3. Split the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57fe6b92-8004-4415-b991-6805b77d9f70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = df_pyspark.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d21b64d7-42f2-42d8-9747-8934edf5d1ae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cdb1b69-d54e-49e7-b309-5e4499b8311f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the linear regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Weight\")\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c7b2756-6ea8-46a1-8d73-b001d7393126",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 5. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aa428f5-42c0-4965-b546-5f4132f4000e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [35.49218657758219,60.205693552170466,2.104162706107436,87.64007047629201,-6.086893869639924,-56.481856043755876]\nIntercept: -640.5095040591044\nRoot Mean Squared Error (RMSE) on test data: 192.96307170017775\nMean Absolute Error (MAE) on test data: 125.10917522565474\nMean Squared Error (MSE) on test data: 37234.747039967944\nMean Absolute Percentage Error (MAPE) on test data: 267.5630248285055%\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "rmse_evaluator = RegressionEvaluator(labelCol=\"Weight\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "\n",
    "# Evaluate the model using MAE\n",
    "mae_evaluator = RegressionEvaluator(labelCol=\"Weight\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "mse_evaluator = RegressionEvaluator(labelCol=\"Weight\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = mse_evaluator.evaluate(predictions)\n",
    "\n",
    "# Calculate MAPE (Mean Absolute Percentage Error)\n",
    "predictions = predictions.withColumn(\"absolute_error\", abs(col(\"prediction\") - col(\"Weight\")))\n",
    "predictions = predictions.withColumn(\"percentage_error\", col(\"absolute_error\") / col(\"Weight\"))\n",
    "mape = predictions.selectExpr(\"mean(percentage_error) as MAPE\").collect()[0][\"MAPE\"] * 100\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(f\"Coefficients: {lr_model.coefficients}\")\n",
    "print(f\"Intercept: {lr_model.intercept}\")\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE) on test data: {mae}\")\n",
    "print(f\"Mean Squared Error (MSE) on test data: {mse}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE) on test data: {mape}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddc78698-4fc3-40a8-b438-921955cda45a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+--------------------+\n|       prediction|Weight|            features|\n+-----------------+------+--------------------+\n|380.5439443293234| 430.0|[1.0,12.444,5.134...|\n|432.3453959285865| 450.0|[1.0,13.6024,4.92...|\n|527.1207177060547| 340.0|[1.0,13.9129,5.07...|\n|552.2866125257455| 500.0|[1.0,14.3714,4.81...|\n|616.8918308237536| 600.0|[1.0,15.438,5.58,...|\n+-----------------+------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Show some sample predictions\n",
    "predictions.select(\"prediction\", \"Weight\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f27ac2b8-5d33-4908-a28b-756cbb7e4a89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the trained logistic regression model\n",
    "model_path = \"./Internship_Sem-6_models/Fish_Weight_Prediction_model\"\n",
    "lr_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2900b7b2-252c-43ab-8f0c-03843b143887",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/Internship_Sem-6_models/Fish_Weight_Prediction_model/data/', name='data/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/Internship_Sem-6_models/Fish_Weight_Prediction_model/metadata/', name='metadata/', size=0, modificationTime=0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"dbfs:/Internship_Sem-6_models/Fish_Weight_Prediction_model\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Fish_Weight_Prediction",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
